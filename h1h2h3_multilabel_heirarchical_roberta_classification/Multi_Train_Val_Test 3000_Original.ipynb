{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 02:19:13.649016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/data2/users/mpagare/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:152: UserWarning: \n",
      "    Found GPU1 Tesla K40c which is of cuda capability 3.5.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "/data2/users/mpagare/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:152: UserWarning: \n",
      "    Found GPU2 Tesla K40c which is of cuda capability 3.5.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "/data2/users/mpagare/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 308/308 [03:50<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.59it/s]\n",
      "Training: 100%|██████████| 308/308 [03:50<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.61it/s]\n",
      "Training: 100%|██████████| 308/308 [03:50<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.62it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.63it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.64it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.65it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.64it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.64it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.64it/s]\n",
      "Training: 100%|██████████| 308/308 [03:49<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.64it/s]\n",
      "Training: 100%|██████████| 308/308 [03:48<00:00,  1.34it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.65it/s]\n",
      "Training: 100%|██████████| 308/308 [03:48<00:00,  1.35it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.65it/s]\n",
      "Training: 100%|██████████| 308/308 [03:48<00:00,  1.35it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.65it/s]\n",
      "Training: 100%|██████████| 308/308 [03:48<00:00,  1.35it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.66it/s]\n",
      "Training: 100%|██████████| 308/308 [03:48<00:00,  1.35it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:12<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1:9].values.tolist()  # Assuming columns 1 to 8 are H1 labels\n",
    "\n",
    "model2_data = pd.read_csv(\"model2.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 9:41].values.tolist()  # Assuming columns 9 to 40 are H2 labels\n",
    "\n",
    "model3_data = pd.read_csv(\"model3.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 41:].values.tolist()  # Assuming columns 41 onwards are H3 labels\n",
    "\n",
    "# Split the data for each hierarchy (adjust the ratios as needed)\n",
    "def split_data(texts, labels, train_ratio, val_ratio, test_ratio):\n",
    "    total_samples = len(texts)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = int(total_samples * test_ratio)\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    val_texts = texts[train_size:train_size + val_size]\n",
    "    test_texts = texts[train_size + val_size:]\n",
    "\n",
    "    train_labels = labels[:train_size]\n",
    "    val_labels = labels[train_size:train_size + val_size]\n",
    "    test_labels = labels[train_size + val_size:]\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "train_texts_h1, val_texts_h1, test_texts_h1, train_labels_h1, val_labels_h1, test_labels_h1 = split_data(texts_h1, labels_h1, 0.7, 0.1, 0.2)\n",
    "train_texts_h2, val_texts_h2, test_texts_h2, train_labels_h2, val_labels_h2, test_labels_h2 = split_data(texts_h2, labels_h2, 0.7, 0.1, 0.2)\n",
    "train_texts_h3, val_texts_h3, test_texts_h3, train_labels_h3, val_labels_h3, test_labels_h3 = split_data(texts_h3, labels_h3, 0.7, 0.1, 0.2)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1\n",
    "        self.labels_h2 = labels_h2\n",
    "        self.labels_h3 = labels_h3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, max_length=self.max_length, padding='max_length', return_token_type_ids=True, truncation=True)\n",
    "    \n",
    "        return {\n",
    "          'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "          'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "          'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float),\n",
    "          'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "          'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create datasets and dataloaders for H1, H2, and H3\n",
    "dataset_h1 = TextDataset(train_texts_h1 + val_texts_h1 + test_texts_h1, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h2 = TextDataset(train_texts_h2 + val_texts_h2 + test_texts_h2, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h3 = TextDataset(train_texts_h3 + val_texts_h3 + test_texts_h3, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "\n",
    "# Split the datasets into train, val, and test for H1, H2, and H3\n",
    "train_size_h1 = len(train_texts_h1)\n",
    "val_size_h1 = len(val_texts_h1)\n",
    "train_size_h2 = len(train_texts_h2)\n",
    "val_size_h2 = len(val_texts_h2)\n",
    "train_size_h3 = len(train_texts_h3)\n",
    "val_size_h3 = len(val_texts_h3)\n",
    "\n",
    "train_dataset_h1, val_dataset_h1, test_dataset_h1 = random_split(dataset_h1, [train_size_h1, val_size_h1, len(test_texts_h1)])\n",
    "train_dataset_h2, val_dataset_h2, test_dataset_h2 = random_split(dataset_h2, [train_size_h2, val_size_h2, len(test_texts_h2)])\n",
    "train_dataset_h3, val_dataset_h3, test_dataset_h3 = random_split(dataset_h3, [train_size_h3, val_size_h3, len(test_texts_h3)])\n",
    "\n",
    "# Create dataloaders for H1, H2, and H3\n",
    "train_dataloader_h1 = DataLoader(train_dataset_h1, batch_size=8, shuffle=True)\n",
    "val_dataloader_h1 = DataLoader(val_dataset_h1,batch_size=8, shuffle=False)  # You can set shuffle to True if you want to shuffle the validation data.\n",
    "train_dataloader_h2 = DataLoader(train_dataset_h2, batch_size=8, shuffle=True)\n",
    "val_dataloader_h2 = DataLoader(val_dataset_h2, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataloader_h3 = DataLoader(train_dataset_h3, batch_size=8, shuffle=True)\n",
    "val_dataloader_h3 = DataLoader(val_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h1, num_labels_h2, num_labels_h3):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.roberta.config.hidden_size, num_labels_h1)\n",
    "        self.fc_h2 = nn.Linear(self.roberta.config.hidden_size, num_labels_h2)\n",
    "        self.fc_h3 = nn.Linear(self.roberta.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids, attention_mask)\n",
    "        logits_h1 = self.fc_h1(self.dropout(outputs.last_hidden_state[:, 0, :]))  # Pooling strategy: [CLS] token\n",
    "        logits_h2 = self.fc_h2(self.dropout(outputs.last_hidden_state[:, 0, :]))  # Pooling strategy: [CLS] token\n",
    "        logits_h3 = self.fc_h3(self.dropout(outputs.last_hidden_state[:, 0, :]))  # Pooling strategy: [CLS] token\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "model = MultiLabelClassifier(num_labels_h1=len(train_labels_h1[0]), num_labels_h2=len(train_labels_h2[0]), num_labels_h3=len(train_labels_h3[0]))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop for H1, H2, and H3\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=\"Training\"):\n",
    "        input_ids = batch['ids'].to(device)\n",
    "        attention_mask = batch['mask'].to(device)\n",
    "        labels_h1 = batch['labels_h1'].to(device)\n",
    "        labels_h2 = batch['labels_h2'].to(device)\n",
    "        labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "        loss_h1 = criterion(logits_h1, labels_h1)\n",
    "        loss_h2 = criterion(logits_h2, labels_h2)\n",
    "        loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "        loss = loss_h1 + loss_h2 + loss_h3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop for H1, H2, and H3\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Validation\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "num_epochs = 5  # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_h1 = train(model, train_dataloader_h1, optimizer, criterion, device)\n",
    "    val_loss_h1, val_preds_h1, _, _, val_labels_h1, _, _ = evaluate(model, val_dataloader_h1, criterion, device)\n",
    "\n",
    "    train_loss_h2 = train(model, train_dataloader_h2, optimizer, criterion, device)\n",
    "    val_loss_h2, _, val_preds_h2, _, _, val_labels_h2, _ = evaluate(model, val_dataloader_h2, criterion, device)\n",
    "\n",
    "    train_loss_h3 = train(model, train_dataloader_h3, optimizer, criterion, device)\n",
    "    val_loss_h3, _, _, val_preds_h3, _, _, val_labels_h3 = evaluate(model, val_dataloader_h3, criterion, device)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - H1: Train Loss: 0.2019, Val Loss: 0.2230\n",
      "Accuracy H1: 0.8348, Precision H1: 0.9617, Recall H1: 0.9697, F1 H1: 0.9657, Avg Precision H1: 0.9899\n",
      "Epoch 5/5 - H2: Train Loss: 0.1843, Val Loss: 0.2155\n",
      "Accuracy H2: 0.6040, Precision H2: 0.8949, Recall H2: 0.7608, F1 H2: 0.8224, Avg Precision H2: 0.8821\n",
      "Epoch 5/5 - H3: Train Loss: 0.1711, Val Loss: 0.1989\n",
      "Accuracy H3: 0.2365, Precision H3: 0.7796, Recall H3: 0.5074, F1 H3: 0.6147, Avg Precision H3: 0.6754\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and print metrics for H1\n",
    "threshold_h1 = 0.5  # You can adjust this threshold as needed\n",
    "val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "avg_precision_h1 = average_precision_score(val_labels_h1, val_preds_h1, average='micro')\n",
    "\n",
    "print(f\"Epoch {epoch+1}/{num_epochs} - H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}\")\n",
    "print(f\"Accuracy H1: {acc_h1:.4f}, Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}, Avg Precision H1: {avg_precision_h1:.4f}\")\n",
    "\n",
    "# Calculate and print metrics for H2\n",
    "threshold_h2 = 0.5  # You can adjust this threshold as needed\n",
    "val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "avg_precision_h2 = average_precision_score(val_labels_h2, val_preds_h2, average='micro')\n",
    "\n",
    "print(f\"Epoch {epoch+1}/{num_epochs} - H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}\")\n",
    "print(f\"Accuracy H2: {acc_h2:.4f}, Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}, Avg Precision H2: {avg_precision_h2:.4f}\")\n",
    "\n",
    "# Calculate and print metrics for H3\n",
    "threshold_h3 = 0.5  # You can adjust this threshold as needed\n",
    "val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "acc_h3 = accuracy_score(val_labels_h3, val_preds_h3_binary)\n",
    "precision_h3 = precision_score(val_labels_h3, val_preds_h3_binary, average='micro')\n",
    "recall_h3 = recall_score(val_labels_h3, val_preds_h3_binary, average='micro')\n",
    "f1_h3 = f1_score(val_labels_h3, val_preds_h3_binary, average='micro')\n",
    "avg_precision_h3 = average_precision_score(val_labels_h3, val_preds_h3, average='micro')\n",
    "\n",
    "print(f\"Epoch {epoch+1}/{num_epochs} - H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}\")\n",
    "print(f\"Accuracy H3: {acc_h3:.4f}, Precision H3: {precision_h3:.4f}, Recall H3: {recall_h3:.4f}, F1 H3: {f1_h3:.4f}, Avg Precision H3: {avg_precision_h3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rough\n",
    "# Calculate and print metrics for H1, H2, and H3\n",
    "    # You can use functions like accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics\n",
    "    acc_h1 = accuracy_score(val_labels_h1, (np.array(val_preds_h1) > 0.5).astype(int))\n",
    "    precision_h1 = precision_score(val_labels_h1, (np.array(val_preds_h1) > 0.5).astype(int))\n",
    "    recall_h1 = recall_score(val_labels_h1, (np.array(val_preds_h1) > 0.5).astype(int))\n",
    "    f1_h1 = f1_score(val_labels_h1, (np.array(val_preds_h1) > 0.5).astype(int))\n",
    "\n",
    "    acc_h2 = accuracy_score(val_labels_h2, (np.array(val_preds_h2) > 0.5).astype(int))\n",
    "    precision_h2 = precision_score(val_labels_h2, (np.array(val_preds_h2) > 0.5).astype(int))\n",
    "    recall_h2 = recall_score(val_labels_h2, (np.array(val_preds_h2) > 0.5).astype(int))\n",
    "    f1_h2 = f1_score(val_labels_h2, (np.array(val_preds_h2) > 0.5).astype(int))\n",
    "\n",
    "    acc_h3 = accuracy_score(val_labels_h3, (np.array(val_preds_h3) > 0.5).astype(int))\n",
    "    precision_h3 = precision_score(val_labels_h3, (np.array(val_preds_h3) > 0.5).astype(int))\n",
    "    recall_h3 = recall_score(val_labels_h3, (np.array(val_preds_h3) > 0.5).astype(int))\n",
    "    f1_h3 = f1_score(val_labels_h3, (np.array(val_preds_h3) > 0.5).astype(int))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}, Acc: {acc_h1:.4f}, Precision: {precision_h1:.4f}, Recall: {recall_h1:.4f}, F1: {f1_h1:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}, Acc: {acc_h2:.4f}, Precision: {precision_h2:.4f}, Recall: {recall_h2:.4f}, F1: {f1_h2:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}, Acc: {acc_h3:.4f}, Precision: {precision_h3:.4f}, Recall: {recall_h3:.4f}, F1: {f1_h3:.4f}\")\n",
    "# You can also add a test loop to evaluate the model on the test set if needed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
